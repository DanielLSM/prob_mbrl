{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "from prob_mbrl import train_regressor, losses, models\n",
    "torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "n_layers = 4\n",
    "layer_width = 200\n",
    "drop_rate = 0.5\n",
    "odims = 1\n",
    "N_ensemble = 100\n",
    "\n",
    "# single gaussian output model\n",
    "model = models.Regressor(\n",
    "    models.dropout_mlp(\n",
    "        1, 2*odims, [layer_width]*n_layers,\n",
    "        nonlin=models.activations.Swish,\n",
    "        weights_initializer=partial(torch.nn.init.xavier_normal_,\n",
    "                                    gain=1),\n",
    "        biases_initializer=partial(torch.nn.init.uniform_, a=-1.0, b=1.0),\n",
    "        dropout_layers=[models.CDropout(drop_rate, temperature=1.0)]*n_layers),\n",
    "        output_density=models.DiagGaussianDensity(odims))\n",
    "\n",
    "# mixture density network\n",
    "n_components = 2\n",
    "mmodel = models.Regressor(\n",
    "    models.dropout_mlp(\n",
    "        1, 2*n_components*odims + n_components, [layer_width]*n_layers,\n",
    "        nonlin=models.activations.Swish,\n",
    "        weights_initializer=partial(torch.nn.init.xavier_normal_,\n",
    "                                    gain=1),\n",
    "        biases_initializer=partial(torch.nn.init.uniform_, a=-1.0, b=1.0),\n",
    "        dropout_layers=[models.CDropout(drop_rate, temperature=1.0)]*n_layers),\n",
    "        output_density=models.MixtureDensity(odims, n_components))\n",
    "\n",
    "# optimizer for single gaussian model\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "opt1 = torch.optim.Adam(params, 1e-3, amsgrad=True)\n",
    "\n",
    "# optimizer for mixture density network\n",
    "params = filter(lambda p: p.requires_grad, mmodel.parameters())\n",
    "opt2 = torch.optim.Adam(params, 1e-3, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 85 samples\n"
     ]
    }
   ],
   "source": [
    "# create training dataset\n",
    "def f(x, multimodal=False):\n",
    "    k = 100\n",
    "    if multimodal:\n",
    "        k *= np.random.choice([-1, 1], x.shape[0])\n",
    "    return k*sum([np.sin(-2*np.pi*(2*k-1)*x)/(2*k-1) for k in range(1, 3)])\n",
    "\n",
    "train_x = np.concatenate([np.arange(-0.6,-0.25,0.01),\n",
    "                          np.arange(0.1,0.25,0.01),\n",
    "                          np.arange(0.65,1.0,0.01),\n",
    "                         ])\n",
    "train_y = f(train_x)\n",
    "train_y += 0.01*np.random.randn(*train_y.shape)\n",
    "X = torch.from_numpy(train_x[:, None])\n",
    "Y = torch.from_numpy(train_y[:, None])\n",
    "\n",
    "model.set_dataset(X, Y)\n",
    "model = model.float()\n",
    "mmodel.set_dataset(X, Y)\n",
    "mmodel = mmodel.float()\n",
    "print 'Dataset size:', train_x.shape[0], 'samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log-likelihood of data: 1.106456: 100%|██████████| 10000/10000 [03:27<00:00, 48.16it/s]\n",
      "log-likelihood of data: -0.592475:  54%|█████▍    | 5407/10000 [03:21<02:50, 26.86it/s]"
     ]
    }
   ],
   "source": [
    "train_regressor(model, iters=10000, batchsize=N_ensemble, resample=True,\n",
    "                optimizer=opt1)\n",
    "train_regressor(mmodel, iters=10000, batchsize=N_ensemble, resample=True,\n",
    "                optimizer=opt2, log_likelihood=losses.gaussian_mixture_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate single gaussian model\n",
    "test_x = np.arange(-3.8,5.3,0.01)\n",
    "ret = []\n",
    "#model.model.resample()\n",
    "for i, x in enumerate(test_x):\n",
    "    x = torch.tensor(x[None]).float()\n",
    "    outs = model(x.expand((N_ensemble, 1)), resample=False)\n",
    "    y = torch.cat(outs[:2], -1)\n",
    "    ret.append(y.cpu().detach().numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "ret = np.stack(ret)\n",
    "ret = ret.transpose(1, 0, 2)\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "for i in range(3):\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "nc = ret.shape[-2]\n",
    "colors = list(plt.cm.rainbow_r(np.linspace(0, 1, nc)))\n",
    "\n",
    "def gaussian_sample(mu, sigma):\n",
    "    z2 = np.random.randn(*mu.shape)\n",
    "    return mu + z2*sigma\n",
    "\n",
    "for i in range(len(ret)):\n",
    "    m, S = ret[i, :, 0], ret[i, :, 1]\n",
    "    samples = gaussian_sample(m, S)\n",
    "    plt.scatter(test_x, m, c=colors[0], s=1)\n",
    "    plt.scatter(test_x, samples, c=colors[0]*0.5, s=1)\n",
    "    #plt.fill_between(test_x, m-S, m+S, color='red', linestyle='--', linewidth=1, alpha = 0.3)\n",
    "m = ret[:, :, 0].mean(0)\n",
    "S = ret[:, :, 0].std(0)\n",
    "#plt.plot(test_x, m, label='nn%d' % i, color='red', linestyle='--', linewidth=2)\n",
    "#plt.fill_between(test_x, m-S, m+S, label='nn%d' % i, color='red', linestyle='--', linewidth=2, alpha = 0.5)\n",
    "#plt.fill_between(test_x, m-2*S, m+2*S, label='nn%d' % i, color='red', linestyle='--', linewidth=2, alpha = 0.25)\n",
    "plt.plot(test_x, f(test_x), linestyle='--', label='true function')\n",
    "plt.scatter(X.cpu().numpy().flatten(), Y.cpu().numpy().flatten())\n",
    "plt.xlabel('$a_t$', fontsize=18)\n",
    "plt.ylabel('$f(s_t, a_t) - s_t$', fontsize=18)\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate mixture density network\n",
    "test_x = np.arange(-3.8,5.3,0.01)\n",
    "ret = []\n",
    "weights = []\n",
    "#mmodel.model.resample()\n",
    "for i, x in enumerate(test_x):\n",
    "    x = torch.tensor(x[None]).float()\n",
    "    outs = mmodel(x.expand((N_ensemble, 1)), resample=False)\n",
    "    y = torch.cat(outs[:2], -2)\n",
    "    ret.append(y.cpu().detach().numpy())\n",
    "    weights.append(outs[2].cpu().detach().numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "ret = np.stack(ret)\n",
    "ret = ret.transpose(1, 0, 2, 3)\n",
    "weights = np.stack(weights)\n",
    "weights = weights.transpose(1, 0, 2)\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "for i in range(3):\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "nc = ret.shape[-1]\n",
    "colors = np.array(list(plt.cm.rainbow_r(np.linspace(0, 1, nc))))\n",
    "\n",
    "def mixture_sample(mu, sigma, pi, colors=None, noise=True):\n",
    "    z1 = np.random.rand(*pi.shape)\n",
    "    k = (np.log(pi+1e-10) + z1).argmax(-1)\n",
    "    idx = np.arange(len(mu))\n",
    "    samples = mu[idx, k]\n",
    "    if noise:\n",
    "        z2 = np.random.randn(*mu.shape[:-1])\n",
    "        samples += z2*sigma[idx, k]\n",
    "\n",
    "    if colors is not None:\n",
    "        return samples, colors[k]\n",
    "    return samples\n",
    "\n",
    "total_samples = []\n",
    "for i in range(len(ret)):\n",
    "    m, S = ret[i, :, 0, :], ret[i, :, 1, :]\n",
    "    samples, c = mixture_sample(m, S, weights[i], colors)\n",
    "    plt.scatter(test_x, samples, c=c*0.5, s=1)\n",
    "    samples, c = mixture_sample(m, S, weights[i], colors, noise=False)\n",
    "    plt.scatter(test_x, samples, c=c, s=1)\n",
    "    total_samples.append(samples)\n",
    "total_samples = np.array(total_samples)\n",
    "m = total_samples.mean(0)\n",
    "S = total_samples.std(0)\n",
    "#plt.plot(test_x, m, label='nn%d' % i, color='red', linestyle='--', linewidth=2)\n",
    "#plt.fill_between(test_x, m-S, m+S, label='nn%d' % i, color='red', linestyle='--', linewidth=2, alpha = 0.5)\n",
    "#plt.fill_between(test_x, m-2*S, m+2*S, label='nn%d' % i, color='red', linestyle='--', linewidth=2, alpha = 0.25)\n",
    "plt.plot(test_x, f(test_x), linestyle='--', label='true function')\n",
    "plt.scatter(X.cpu().numpy().flatten(), Y.cpu().numpy().flatten())\n",
    "plt.xlabel('$a_t$', fontsize=18)\n",
    "plt.ylabel('$f(s_t, a_t) - s_t$', fontsize=18)\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
